{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aabd1386",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "- `DummyRegressor` helps in creating a baseline for regression.\n",
    "    - It makes a prediction as specified by the strategy.\n",
    "    - Strategy is based on some statistical property of the training set or user specified value.\n",
    "    - Strategy:\n",
    "        - mean\n",
    "        - median\n",
    "        - quantile\n",
    "        - constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f13deba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dummy list for calling list\n",
    "\n",
    "X_train, X_test, y_train, y_test = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b609901",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "dummy_regr = DummyRegressor(strategy='mean')\n",
    "dummy_regr.fit(X_train, y_train)\n",
    "dummy_regr.predict(X_test)\n",
    "dummy_regr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb38c56",
   "metadata": {},
   "source": [
    "### How is Linear Regression Model Trained?\n",
    "\n",
    "_Step 1_: Instantiate object of a suitable linear regression estimator from one of the following two options\n",
    "- Normal Eqution\n",
    "- Iteraive optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d8eb177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Equation\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linear_regr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb7f47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterative Optimisation\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "linear_regr = SGDRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f60eec",
   "metadata": {},
   "source": [
    "_Step 2_ : Call fit method on linear regression object with training feature matrix and label vector as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5523fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linear_regr = LinearRegression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de47079",
   "metadata": {},
   "source": [
    "## SGDRegressor Estimator\n",
    "\n",
    "- Implements stochastic gradient descent\n",
    "- Use for large training set up (> 10k samples)\n",
    "- Provides greater control on optimization process through provision for hyperparameter settings.\n",
    "- loss parameters:\n",
    "    - `loss = 'squared error'`\n",
    "    - `loss = 'huber'`\n",
    "- Penalty params:\n",
    "    - `penalty = l1`\n",
    "    - `penalty = l2`\n",
    "    - `penalty = elsaticnet`\n",
    "- Learning rate:\n",
    "    - `learning_rate = 'constant`\n",
    "    - `learning_rate = 'optimal`\n",
    "    - `learning_rate = 'invscaling`\n",
    "    - `learning_rate = 'adaptive`\n",
    "- Stopping:\n",
    "    - `early_stopping = 'True'`\n",
    "    - `early_stopping = 'False'`\n",
    "\n",
    "- It is good to use random_state to seed your choice\n",
    "    - `random_state = 42`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47c8568",
   "metadata": {},
   "source": [
    "### How to perform feature scaling for SGDRegressor?\n",
    "\n",
    "SGD is sensitive to feature scaling, so it is highly recommended to scale input feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c6aba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sgd = Pipeline([\n",
    "    ('feature_scaling', StandardScaler()),\n",
    "    ('sgr_regressor', SGDRegressor())\n",
    "])\n",
    "\n",
    "sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ee183e",
   "metadata": {},
   "source": [
    "### How to shuffle training data after each epoch in SGDRegressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da64a389",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "linear_regr = SGDRegressor(shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add4a0f7",
   "metadata": {},
   "source": [
    "### How to use set learning rate in SGDRegreesor?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c901b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "linear_regr = SGDRegressor(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c018613",
   "metadata": {},
   "source": [
    "### How to use set constant learning rate ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093c5948",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "linear_regr = SGDRegressor(learning_rate='constant', eta0=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a693cfda",
   "metadata": {},
   "source": [
    "### How to use set adaptive learning rate ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abb00590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "linear_regr = SGDRegressor(learning_rate='adaptive', eta0=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c254f7e4",
   "metadata": {},
   "source": [
    "### How to use set #epochs in SGDRegreesor?\n",
    "\n",
    "- Set max_iter to desired #epochs. The default value is 1000.\n",
    "- Remember one epoch is one full pass over the training data.\n",
    "- SGD converges after observing approximately 10Â° training samples. Thus, a reasonable first guess for the number of iterations for n sampled training set is: \n",
    "    - max_iter = np.ceil(10^6/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cd29fa",
   "metadata": {},
   "source": [
    "### How to use set stopping criteria in SGDRegreesor?\n",
    "\n",
    "- Option 1:\n",
    "    - `tol`, `n_iter_no change, max_iter`\n",
    "- Option 2:\n",
    "    - `early_stopping`, `validation_fraction=`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a21f0e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "linear_regr = SGDRegressor(loss='squared_error', max_iter=500, tol= 3e-3, n_iter_no_change=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "598519bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "linear_regr = SGDRegressor(loss='squared_error', early_stopping=True, validation_fraction=0.2, max_iter=500, tol= 3e-3, n_iter_no_change=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ab1764",
   "metadata": {},
   "source": [
    "### How to use different loss functions in SGDRegreesor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c731f2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "linear_regr = SGDRegressor(loss='squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70272da5",
   "metadata": {},
   "source": [
    "### How to use averaged SGD?\n",
    "\n",
    "Averaged SGD updates the weight vector to average of weights from previous updates.\n",
    "\n",
    "- Option #1: Averaging across all updates\n",
    "- Option #2: Set average to int value.\n",
    "    - Averaging begins once the total number of samples seen reaches average\n",
    "    - Setting average=10 starts averaging after seeing 10 samples\n",
    "    - Averaged SGD works best with a larger number of features and a higher eta0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31849d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#option1\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "linear_regr = SGDRegressor(average=True)\n",
    "\n",
    "#option2\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "linear_regr = SGDRegressor(average=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eaec0a",
   "metadata": {},
   "source": [
    "### How do we initialize SGD with weight vector of the previous run?\n",
    "\n",
    "set `warm_start=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4172f217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn. linear_model import SGDRegressor\n",
    "import numpy as np\n",
    "linear_regressor = SGDRegressor(warm_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49163ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sgd_reg = SGDRegressor(\n",
    "#     max_iter=1,\n",
    "#     tol= -np.inf,\n",
    "#     warm_start=True,\n",
    "#     penalty=None,\n",
    "#     learning_rate=\"constant\",\n",
    "#     eta0=0.0005\n",
    "# )\n",
    "\n",
    "# val_errors = []\n",
    "# for epoch in range(1000):\n",
    "#     sgd_reg.fit(X_train, y_train)\n",
    "#     val_pred = sgd_reg.predict(X_val)\n",
    "#     val_errors = mean_squared_error(y_val, val_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c287201d",
   "metadata": {},
   "source": [
    "## Model Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73db86bd",
   "metadata": {},
   "source": [
    "### Accessing the Weights of a Trained Linear Regression Model\n",
    "\n",
    "For a linear regression model, the prediction is given by:\n",
    "\n",
    "$$\n",
    "\\hat{y} = w_0 + w_1 x_1 + w_2 x_2 + \\dots + w_m x_m = \\mathbf{w}^T \\mathbf{x}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Model Weights (Coefficients)\n",
    "\n",
    "The weights  \n",
    "\n",
    "$$\n",
    "w_1, w_2, \\dots, w_m\n",
    "$$\n",
    "\n",
    "are stored in the **`coef_`** attribute of the trained model.\n",
    "\n",
    "```python\n",
    "linear_regressor.coef_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a98d27",
   "metadata": {},
   "source": [
    "## Model inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad00757",
   "metadata": {},
   "source": [
    "### How to make predictions on new data in Linear Regression model?\n",
    "\n",
    "- **Step 1:** Arrange data for prediction in a **feature matrix** of shape `(#samples, #features)` or in sparse matrix format.\n",
    "\n",
    "- **Step 2:** Call the `predict` method on the **linear regression object** with the **feature matrix** as an argument.\n",
    "\n",
    "```python\n",
    "# Predict labels for feature matrix X_test\n",
    "linear_regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bad5131",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a86383",
   "metadata": {},
   "source": [
    "### General Steps in model evaluation\n",
    "\n",
    "- STEP 1: Split data into train and test\n",
    "- STEP 2: Fit linear regression estimator on training set.\n",
    "- STEP 3: Calculate training error (a.k.a. empirical error)\n",
    "- STEP 4: Calculate test error (a.k.a. generalization error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7331bec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = [4,5,4,3,6]\n",
    "y = [3,4,5,2,4]\n",
    "y_predicted = [3,2,3,2,4]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2719f30f",
   "metadata": {},
   "source": [
    "### How to evaluate trained Linear Regression model?\n",
    "- Using score method on linear regression object:\n",
    "- The score returns R2 or coefficient of determination\n",
    "- R2 = 1 - (u/v)\n",
    "- u (residual sum of square) = (Xw-y)^T (Xw-y)\n",
    "- v = (y-y^_mean)^T((y-y^_mean))\n",
    "- Best possible R is 1.0\n",
    "- A constant model that always predicts the expected value of y, would get a score of 0.0\n",
    "- The score can be negative because the model can be arbitrarily worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cf7721",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e59d3b",
   "metadata": {},
   "source": [
    "### Evaluation Metrics\n",
    "\n",
    "sklearn provides a bunch of regression metrics to evaluate performance of the trained estimator on the evaluation set.\n",
    "\n",
    "`mean_absolute_error`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823fa2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "eval_score = mean_absolute_error(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3063a1",
   "metadata": {},
   "source": [
    "`mean_squarred_error`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dbc185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "eval_score = mean_squared_error(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec56fe05",
   "metadata": {},
   "source": [
    "`mean_squarred_log_error`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e971f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "eval_score = mean_squared_log_error(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098b7ba1",
   "metadata": {},
   "source": [
    "`mean_absolute_percentage_error`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aee77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "eval_score = mean_absolute_percentage_error(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919dd43e",
   "metadata": {},
   "source": [
    "`mean_absolute_error`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4da9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "eval_score = mean_absolute_error(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47506016",
   "metadata": {},
   "source": [
    "### How to evaluate regression model on worst case error?\n",
    "\n",
    "Use `max-error `\n",
    "Worst case error on train set can be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c022ca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import max_error\n",
    "train_error = max_error(y_train, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c460279",
   "metadata": {},
   "source": [
    "You can convert error to score by using neg_ suffix.\n",
    "`mean_squared_error1` -> `neg_mean_squared_error`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e739a01",
   "metadata": {},
   "source": [
    "## Model Performance and Data Splits\n",
    "\n",
    "In case we get **comparable performance on train and test** with this split, is this performance guaranteed on other splits too?\n",
    "\n",
    "* **Is the test set sufficiently large?**\n",
    "    * In case it is small, the test error obtained may be **unstable** and would not reflect the true test error on a large test set.\n",
    "* **What is the chance that the easiest examples were kept aside as test by chance?**\n",
    "    * If this happens, it would lead to an **optimistic estimation** of the true test error.\n",
    "\n",
    "We can use **Cross-Validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5115dbae",
   "metadata": {},
   "source": [
    "### K-fold\n",
    "\n",
    "- Uses KFold cross validation iterator, that divides training data into 5 folds.\n",
    "- In each run, it uses 4 folds for training and 1 for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a459da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "linear_regr = LinearRegression()\n",
    "score = cross_val_score(linear_regr,X,y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d64fed",
   "metadata": {},
   "source": [
    "### Leave one out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd93554",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "linear_regr = LinearRegression()\n",
    "loocv = LeaveOneOut()\n",
    "score = cross_val_score(linear_regr,X,y, cv=loocv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583c9407",
   "metadata": {},
   "source": [
    "### shufflesplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e60ea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "shufflesplit = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "score = cross_val_score(linear_regr, X,y, cv=shufflesplit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3aa9da9",
   "metadata": {},
   "source": [
    "### How to obtain test scores from different folds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41d39d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_validate\n",
    "\n",
    "# cv = ShuffleSplit(n_splits=40, test_size=0.3, random_state=0)\n",
    "# cv_results = cross_validate(regressor, data, target, cv=cv, scoring=\"neg_mean_absolute_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ee11f4",
   "metadata": {},
   "source": [
    "# Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f153e5a6",
   "metadata": {},
   "source": [
    "- Step 1: Apply polynomial transformation on the feature matrix.\n",
    "- Step 2: Learn linear regression model (via normal equation or SGD) on the transformed feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dee6549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly_mode = Pipeline([\n",
    "    ('polynomial_transformation', PolynomialFeatures(degree=2, interaction_only=True),\n",
    "    ('linear_regr', LinearRegression()))\n",
    "])\n",
    "\n",
    "poly_mode.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a48f1c1",
   "metadata": {},
   "source": [
    "### Regularization\n",
    "\n",
    "How to perform ridge regularization with specific regularization rate?\n",
    "\n",
    "- Option #1\n",
    "    - Step 1: Instantiate object of Ridge estimator\n",
    "    - Step 2: Set parameter alpha to the required regularization rate.\n",
    "- Option #2\n",
    "    - Instantiate object of SGDRegressor estimator\n",
    "    - Set parameter alpha to the required regularization rate\n",
    "and penalty = 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c527a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(alpha= 1e-3)\n",
    "\n",
    "#option 2\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "sgd = SGDRegressor(alpha=1e-3, penalty='12')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0766d00",
   "metadata": {},
   "source": [
    "### How to perform ridge regularization in polynomial regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b89de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_model = Pipeline([\n",
    "    ('polynomial_transformation', PolynomialFeatures()),\n",
    "    ('Ridge', Ridge(alpha=1e-3))\n",
    "])\n",
    "\n",
    "poly_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3699a16d",
   "metadata": {},
   "source": [
    "Same for `Lasso`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cbe1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "poly_model = Pipeline([\n",
    "    ('polynomial_transformation', PolynomialFeatures()),\n",
    "    ('Ridge', Lasso(alpha=1e-3))\n",
    "])\n",
    "\n",
    "poly_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c8a8fe",
   "metadata": {},
   "source": [
    "Use both `Ridge` and `Lasso`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038cfeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "poly_model = Pipeline([\n",
    "    ('polynomial_transformation', PolynomialFeatures(degree=2)),\n",
    "    ('elsatic_net', SGDRegressor(penalty='elasticnet', l1_ratio=0.3))\n",
    "])\n",
    "\n",
    "poly_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7b1d33",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb951e4",
   "metadata": {},
   "source": [
    "#### How to set these hyperparameters?\n",
    "\n",
    "Hyper parameter search consists of\n",
    "- an estimator (regressor or classifier);\n",
    "- a parameter space;\n",
    "- a method for searching or sampling candidates;\n",
    "- a cross-validation scheme; and\n",
    "- a score function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9f1175",
   "metadata": {},
   "source": [
    "#### Two generic HPT approaches implemented in sklearn are:\n",
    "\n",
    "- GridSearchCV exhaustively considers all parameter combinations for specified values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc733c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'C':[1,10,100,100], 'kernal': ['linear']}]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
