{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7908946",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "Real world data is never clean\n",
    "- Sklearn provided transformers to pre-process the data\n",
    "- Sklearn provides pipeline for making it easier to chain multiple transforms together and apply them uniformly across train, eval and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cbdc61",
   "metadata": {},
   "source": [
    "### Typical Problems include\n",
    "- Missing Values \n",
    "    - Numerical values are not on the same scale\n",
    "        - Categorical Values needs to be represented in a sensible numerical manner\n",
    "- Too many features, need to remove them\n",
    "    - Extract features from non-numerical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085e7a7b",
   "metadata": {},
   "source": [
    "Sklearn provides a library of transformers for data preprocessing.\n",
    "- Data cleaning `(sklearn.preprocessing)` such as standardization, missing value imputation, etc.\n",
    "- Feature extraction `(sklearn.feature_extraction)`\n",
    "- Feature reduction `(sklearn.decomposition.pca)`\n",
    "- Feature expansion `(sklearn.kernel_approximation)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfdc4e4",
   "metadata": {},
   "source": [
    "### Tranfomer methods\n",
    "\n",
    "- `fit()` method learns model parameters from a training set.\n",
    "- `transform()` method applies the learnt transformation to the new data.\n",
    "- `fit_transform()` performs function of both `fit()` and `transform()` methods and is more convenient and efficient to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e25d84",
   "metadata": {},
   "source": [
    "`sklearn.feature_extraction` has useful APIs to extract features from data:\n",
    "- DictVectorizer - Convertes data from dictonary to a Matrix\n",
    "- FeatureHasher - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5257dbbe",
   "metadata": {},
   "source": [
    "### feature extraction from images and text\n",
    "- `sklearn. feature_extraction. image.*` has useful APIs to extract features from image data. Find out more about them in sklearn user guide at the following link: Feature Extraction from Images.\n",
    "- `sklearn.feature_extraction.text.*` has useful APIs to extract features from text data. Find out more about them in sklearn user guide at the following link: Feature Extraction from Text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9121fae",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "Missing values occur due to errors in data capture such as sensor malfunctioning, measurement errors etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e55387",
   "metadata": {},
   "source": [
    "- `sklearn.impute` API provides functionality to fill missing values in a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1fb276",
   "metadata": {},
   "source": [
    "- SimpleImputer\n",
    "- KNNImputer\n",
    "\n",
    "Can be used to fill missing data.\n",
    "\n",
    "`MissingIndicator` provides indicators for missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86607b6",
   "metadata": {},
   "source": [
    "### SimpleImputer\n",
    "\n",
    "- Fills missing values with one of the following strategies:\n",
    "'mean', 'median' , 'most_frequent' and 'constant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ed77201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# si = SimpleImputer(strategy = 'mean)\n",
    "# si.fit_transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315e1b33",
   "metadata": {},
   "source": [
    "### KNNImputer\n",
    "\n",
    "- Uses k-nearest neighbours approach to fill missing values in a dataset.\n",
    "- The missing value of an attribute in a specific example is filled with the mean value of the same attribute of n_neighbors closest neighbors.\n",
    "- The nearest neighbours are decided based on Euclidean distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c9e84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knni = KNNImputer(n_neighnours = 2, weights='uniform')\n",
    "# knni.fit_transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a066b7ef",
   "metadata": {},
   "source": [
    "It is useful to indicate the presence of missing values in the dataset.\n",
    "- MissingIndicator helps us get those indications.\n",
    "    - It returns a binary matrix,\n",
    "        - True values correspond to missing entries in original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7dd53e",
   "metadata": {},
   "source": [
    "### Using SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84158313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.,  2.,  3.],\n",
       "       [ 4.,  2.,  6.],\n",
       "       [10.,  2.,  9.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "X = [[np.nan, 2, 3], [4, np.nan, 6], [10, np.nan, 9]]\n",
    "mean_imputer = SimpleImputer(strategy=\"mean\")\n",
    "mean_imputer.fit (X)\n",
    "mean_imputer.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d24e045",
   "metadata": {},
   "source": [
    "### Using KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f5945b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 2. , 4. ],\n",
       "       [3. , 4. , 3. ],\n",
       "       [5.5, 6. , 5. ],\n",
       "       [8. , 8. , 7. ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "X = np.array([[1,2,np.nan], [3,4,3], [np.nan,6,5], [8,8,7]])\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dca700a",
   "metadata": {},
   "source": [
    "## Categorical Transfomer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca1a37b",
   "metadata": {},
   "source": [
    "### OneHotEncoder\n",
    "\n",
    "- Encodes categorical feature or label as a one-hot numeric array.\n",
    "- Creates one binary column for each of K unique values.\n",
    "- Exactly one column has 1 in it and rest have 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d35d52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ohe = OneHotEncode()\n",
    "# ohe.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55031806",
   "metadata": {},
   "source": [
    "### LabelEncoder\n",
    "Encodes target labels with value between 0 and K - 1, where K is number of distinct values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4318591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# le = LabelEncoder()\n",
    "# le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfd5805",
   "metadata": {},
   "source": [
    "### OrdinalEncoder\n",
    "\n",
    "Encodes categorical features with value between 0 and K - 1, where K is number of distinct values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "317c06e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oe = OrdinalEncoder()\n",
    "# oe.fit_transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2e8147",
   "metadata": {},
   "source": [
    "### LabelBinarizer\n",
    "\n",
    "- Several regression and binary classification can be extended o multi-class setup in one-vs-all fashion.\n",
    "- This involves training a single regressor or classifier per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d4a864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lb = LabelBinarizer()\n",
    "# lb.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22ab1eb",
   "metadata": {},
   "source": [
    "### MultiLabelBinarizer\n",
    "\n",
    "Encodes categorical features with value between 0 and K - 1, where K is number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003d973f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlb = MultiLabelBinarizer()\n",
    "# mlb.fit_transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308c385b",
   "metadata": {},
   "source": [
    "### add_dummy_feature\n",
    "\n",
    "Augments dataset with a column vector, each value in the column vector is 1. To hadle biasedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f42ef474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_dummy_feature(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb369165",
   "metadata": {},
   "source": [
    "## Numerical Tranformer\n",
    "\n",
    "- Feature Scaling\n",
    "- Polynomial Tranformation\n",
    "- Discretization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4209cda",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "\n",
    "- Numerical features with different scales leads to slower convergence of iterative optimization procedures.\n",
    "- It is a good practice to scale numerical features so that all of them are on the same scale.\n",
    "- Three feature scaling APls are available in sklearn\n",
    "    - StandardScaler\n",
    "        - $$ x' = \\frac{(x-mu)}{sigma}$$\n",
    "    - MinMaxScaler\n",
    "        - $$ x` = \\frac{(x-x.min)}{(x.max-x.min)}$$\n",
    "        - All the values fall within range [0,1]\n",
    "    - MaxAbsScaler\n",
    "        - It transforms the original features vector x into new feature vector x' so that all values fall within range [-1, 1]\n",
    "        - $$ x' = \\frac{(x)}{{MaxAbsoluteValue}}$$\n",
    "        - $$ MaxAbsoluteValue = max(x.max , |x.min|)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8373768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## StandardScaler\n",
    "\n",
    "# ss = StandardScaler()\n",
    "# ss.fit_transform()\n",
    "\n",
    "## MinMaxScaler\n",
    "\n",
    "# mms = MinMaxScaler()\n",
    "# mms.fit_transfornm()\n",
    "\n",
    "## MaxAbsScaler()\n",
    "\n",
    "# mas = MaxAbsScaler()\n",
    "# mas.fit_transform(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52cdf41",
   "metadata": {},
   "source": [
    "### FunctionTransformer()\n",
    "\n",
    "Constructs transformed features by applying a user defined function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7fcf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft = FunctionTransformer(numpy.log2)\n",
    "# ft.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066fadbc",
   "metadata": {},
   "source": [
    "### Polynomial Transformation\n",
    "\n",
    "Generates a new feature matrix consisting of all polynomial combinations of the features with degree less than or equal to the specified degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc7acffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pf = PolynomialFeatures(degree=2)\n",
    "# pf.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be79cdf1",
   "metadata": {},
   "source": [
    "### KBinDiscretizer\n",
    "\n",
    "- Divides a continuous variable into bins.\n",
    "- One hot encoding or ordinal encoding is further applied to the bin labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75f2ad25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KBinsDiscretizer(\n",
    "# n_bins=5,\n",
    "# strategy='uniforn',\n",
    "# encode = 'ordinal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752d5fc7",
   "metadata": {},
   "source": [
    "### Outliers Removal\n",
    "\n",
    "- IQR method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f347482f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.875 34.875\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "data = np.array([1, 12, 14, 15, 17, 19, 21, 23, 26, 36])\n",
    "\n",
    "iqr = np.quantile(data, 0.75) - np.quantile(data, 0.25)\n",
    "lower_bound = np.quantile(data, 0.25) - 1.5*iqr\n",
    "upper_bound = np.quantile(data, 0.75) + 1.5*iqr\n",
    "\n",
    "print(lower_bound, upper_bound)\n",
    "\n",
    "# plt.boxplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d9094f",
   "metadata": {},
   "source": [
    "- Z-Score method\n",
    "    - Calculate mean and std, and calculate Z-Score : (x-mu)/sigma\n",
    "- Any point above or below Z-Score is calculated as Outlier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
